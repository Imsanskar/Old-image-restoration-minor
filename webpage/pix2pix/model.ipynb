{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3459123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torchvision.datasets as dset\n",
    "from data import image_manipulation\n",
    "from data import dataloader as img_dataloader\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349798f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed for reproducibility\n",
    "random_seed = 69\n",
    "\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57607a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of workers for dataloader\n",
    "no_of_workers = 4\n",
    "\n",
    "# root of the data\n",
    "data_root = \"data/train/\"\n",
    "\n",
    "# batch size\n",
    "batch_size = 1\n",
    "\n",
    "#no of epochs\n",
    "n_epochs = 10\n",
    "\n",
    "# learning rate\n",
    "lr = 0.0002\n",
    "\n",
    "# betas for adam\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "\n",
    "# image size\n",
    "image_height = 256\n",
    "image_width = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee454ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use an image folder dataset the way we have it setup.\n",
    "# Create the dataset\n",
    "dataset = dset.ImageFolder(root=data_root,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True,\n",
    "                                         num_workers = no_of_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dde0879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1916734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetDown(nn.Module):\n",
    "    def __init__(self, in_size, out_size, normalize = True, dropout = 0.0):\n",
    "        super(UNetDown, self).__init__()\n",
    "        layers = [\n",
    "            nn.Conv2d(in_size, out_size, 4, 2, 1, bias = False)\n",
    "        ]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_size))\n",
    "            \n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        \n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d680b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetUp(nn.Module):\n",
    "    def __init__(self, in_size, out_size, dropout = 0.0):\n",
    "        super(UNetUp, self).__init__()\n",
    "\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_size, out_size, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(out_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, skip_input):\n",
    "        x = self.model(x)\n",
    "        x = torch.cat((x, skip_input), 1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2ffefec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(GeneratorUNet, self).__init__()\n",
    "        \n",
    "        self.down1 = UNetDown(in_channels, 64, normalize=False)\n",
    "        self.down2 = UNetDown(64, 128)\n",
    "        self.down3 = UNetDown(128, 256)\n",
    "        self.down4 = UNetDown(256, 512, dropout=0.5)\n",
    "        self.down5 = UNetDown(512, 512, dropout=0.5)\n",
    "        self.down6 = UNetDown(512, 512, dropout=0.5)\n",
    "        self.down7 = UNetDown(512, 512, dropout=0.5)\n",
    "        self.down8 = UNetDown(512, 512, normalize=False, dropout=0.5)\n",
    "\n",
    "        self.up1 = UNetUp(512, 512, dropout=0.5)\n",
    "        self.up2 = UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up3 = UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up4 = UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up5 = UNetUp(1024, 256)\n",
    "        self.up6 = UNetUp(512, 128)\n",
    "        self.up7 = UNetUp(256, 64)\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(128, out_channels, 4, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # U-Net generator with skip connections from encoder to decoder\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        d8 = self.down8(d7)\n",
    "        \n",
    "        # unet connections\n",
    "        u1 = self.up1(d8, d7)\n",
    "        u2 = self.up2(u1, d6)\n",
    "        u3 = self.up3(u2, d5)\n",
    "        u4 = self.up4(u3, d4)\n",
    "        u5 = self.up5(u4, d3)\n",
    "        u6 = self.up6(u5, d2)\n",
    "        u7 = self.up7(u6, d1)\n",
    "\n",
    "        return self.final(u7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fde2f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
    "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalization:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels * 2, 64, normalization=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img_A, img_B):\n",
    "        # Concatenate image and condition image by channels to produce input\n",
    "        img_input = torch.cat((img_A, img_B), 1)\n",
    "        return self.model(img_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d8ee04",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "887a03ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Generator Found\n",
      "Discriminator Found\n",
      "(1, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "#initialize model classes\n",
    "generator = GeneratorUNet()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "\n",
    "# check if cuda is avialbale\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(cuda)\n",
    "\n",
    "# initialize weights if the model is not found in the paths\n",
    "if os.path.exists(\"saved_models/generator_49.pth\"):\n",
    "    print(\"Generator Found\")\n",
    "    generator.load_state_dict(torch.load(\"saved_models/generator_49.pth\", map_location = device))\n",
    "else:\n",
    "    generator.apply(weights_init_normal)\n",
    "                                         \n",
    "if os.path.exists(\"saved_models/discriminator_49.pth\"):\n",
    "    print(\"Discriminator Found\")\n",
    "    discriminator.load_state_dict(torch.load(\"saved_models/discriminator.pth\", map_location = device))\n",
    "else:\n",
    "    discriminator.apply(weights_init_normal)\n",
    "\n",
    "# model loss functions\n",
    "loss_fn_generator = torch.nn.MSELoss() # mean squared loss\n",
    "loss_fn_disc = torch.nn.L1Loss() #pixel wise loss\n",
    "\n",
    "# to cuda if cuda is avaiable\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "loss_fn_disc.to(device)\n",
    "loss_fn_generator.to(device)\n",
    "    \n",
    "# optimizers\n",
    "optimier_G = torch.optim.Adam(generator.parameters(), betas=(beta_1, beta_2), lr=lr)\n",
    "optimier_D = torch.optim.Adam(discriminator.parameters(), betas=(beta_1, beta_2), lr=lr)\n",
    "\n",
    "# Loss weight of L1 pixel-wise loss between translated image and real image\n",
    "lambda_pixel = 100\n",
    "\n",
    "# Calculate output of image discriminator (PatchGAN)\n",
    "patch = (1, image_height // 2 ** 4, image_width // 2 ** 4)\n",
    "print(patch)\n",
    "\n",
    "# Tensor type\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6626e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # transform to tensor\n",
    "    transforms.Resize((256, 256)) # Resize the image to constant size\n",
    "])\n",
    "\n",
    "# create a dataloader\n",
    "pair_image_dataloader = img_dataloader.ImageDataset(\"./data/train/old_images\", \"./data/train/reconstructed_images\", transform)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    pair_image_dataloader,\n",
    "    batch_size = 5,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_dataset = img_dataloader.ImageDataset(\"./data/val/old_image\", \"./data/val/reconstructed_image\", transform)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    shuffle = True,\n",
    "    batch_size = 2\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57f79395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 5.80 GiB total capacity; 3.99 GiB already allocated; 422.81 MiB free; 4.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_403438/3957094055.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# GAN loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mfake_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fake sample generated by generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mpred_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# prediction using discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# check if the sample is valid or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/imsanskar/My_files/Projects/Minor/env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_403438/1204503335.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mu7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/imsanskar/My_files/Projects/Minor/env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/imsanskar/My_files/Projects/Minor/env/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/imsanskar/My_files/Projects/Minor/env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/imsanskar/My_files/Projects/Minor/env/lib/python3.9/site-packages/torch/nn/modules/upsampling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign_corners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/imsanskar/My_files/Projects/Minor/env/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor)\u001b[0m\n\u001b[1;32m   3710\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3711\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3712\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3713\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3714\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 5.80 GiB total capacity; 3.99 GiB already allocated; 422.81 MiB free; 4.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for i, batch in tqdm(enumerate(dataloader)):\n",
    "        real_A = batch['A'] # old image\n",
    "        real_B = batch['B'] # new image\n",
    "        \n",
    "        # train generator\n",
    "        optimier_G.zero_grad()\n",
    "        \n",
    "         # Adversarial ground truths\n",
    "        valid = Variable(Tensor(np.ones((real_A.size(0), *patch))), requires_grad=False) # ground truth for valid\n",
    "        fake = Variable(Tensor(np.zeros((real_A.size(0), *patch))), requires_grad=False) # ground truth for invalid\n",
    "        \n",
    "        \n",
    "        # GAN loss\n",
    "        fake_B = generator(real_A.to(device)) # fake sample generated by generator\n",
    "        pred_fake = discriminator(fake_B.to(device), real_B.to(device)) # prediction using discriminator\n",
    "        loss_generator = loss_fn_generator(pred_fake.to(device), valid.to(device)) # check if the sample is valid or not\n",
    "        \n",
    "        loss_pixel = loss_fn_disc(fake_B.to(device), real_B.to(device)) # calculate the pixel wise loss\n",
    "        \n",
    "        # total loss\n",
    "        loss_G = loss_generator + lambda_pixel * loss_pixel # total loss of the generator\n",
    "        \n",
    "        loss_G.backward()\n",
    "        optimier_G.step()\n",
    "        \n",
    "        ## Train discriminator\n",
    "        optimier_D.zero_grad()\n",
    "        \n",
    "        # Real loss\n",
    "        pred_real = discriminator(real_B.to(device), real_A.to(device)) # loss to check real or not\n",
    "        loss_real = loss_fn_generator(pred_real, valid)\n",
    "\n",
    "        # Fake loss\n",
    "        pred_fake = discriminator(fake_B.detach().to(device), real_A.to(device)) # loss to check fake or not\n",
    "        loss_fake = loss_fn_generator(pred_fake.to(device), fake.to(device))\n",
    "\n",
    "        # Total loss\n",
    "        loss_D = 0.5 * (loss_real + loss_fake) # total loss of the discriminator\n",
    "        \n",
    "        loss_D.backward()\n",
    "        optimier_D.step()\n",
    "        \n",
    "        # for logging\n",
    "        print(f\"Generator Error: {torch.linalg.norm(loss_G).item()}, epoch: {epoch}, itr: {i}\")\n",
    "        print(f\"Discriminator Error: {torch.linalg.norm(loss_D).item()}, epoch: {epoch}, itr: {i}\")\n",
    "        \n",
    "        # train with only 5000 images\n",
    "        if i % 500 ==  0 and i > 0:\n",
    "            break\n",
    "            \n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "055af4cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_537537/2314581082.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mval_dataloader_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m output_image = image_manipulation.np_to_pil(\n\u001b[1;32m      9\u001b[0m     \u001b[0mgenerated_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# generator.load_state_dict(torch.load(\"saved_models/generator_test.pth\", map_location = device))\n",
    "test_image_index = 0\n",
    "\n",
    "generator.load_state_dict(torch.load(\"saved_models/generator_49.pth\", map_location = device))\n",
    "generator.eval()\n",
    "val_dataloader_list = list(next(iter(val_dataloader)))\n",
    "generated_image = generator(val_dataloader_list[0]['A'].unsqueeze(0).to(device)).detach().cpu().numpy()[0]\n",
    "output_image = image_manipulation.np_to_pil(\n",
    "    generated_image\n",
    ")\n",
    "original_image = image_manipulation.np_to_pil(\n",
    "    val_dataloader_list[test_image_index]['A'].detach().cpu().numpy()\n",
    ")\n",
    "\n",
    "new_image = Image.new(output_image.mode, (512, 256))\n",
    "\n",
    "new_image.paste(original_image, (0, 0))\n",
    "new_image.paste(output_image, (256, 0))\n",
    "\n",
    "new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "591d0a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generator.load_state_dict(torch.load(\"saved_models/generator.pth\", map_location = device))\n",
    "generator.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00eee980",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidSchema",
     "evalue": "No connection adapters were found for 'data:image/jpeg;base64,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'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidSchema\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_537537/1088877277.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.rootschat.com/forum/index.php?action=dlattach;topic=682420.0;attach=393468\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data:image/jpeg;base64,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\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0moriginal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m output_image = image_manipulation.np_to_pil(\n",
      "\u001b[0;32m/media/imsanskar/My_files/Projects/Minor/env/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/imsanskar/My_files/Projects/Minor/env/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/imsanskar/My_files/Projects/Minor/env/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    527\u001b[0m         }\n\u001b[1;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/imsanskar/My_files/Projects/Minor/env/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;31m# Get the appropriate adapter to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0madapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# Start time (approximately) of the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/imsanskar/My_files/Projects/Minor/env/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget_adapter\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;31m# Nothing matches :-/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mInvalidSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No connection adapters were found for {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidSchema\u001b[0m: No connection adapters were found for 'data:image/jpeg;base64,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'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "link = \"https://www.rootschat.com/forum/index.php?action=dlattach;topic=682420.0;attach=393468\"\n",
    "response = requests.get(link)\n",
    "original_image = Image.open(BytesIO(response.content)).resize((256, 256))\n",
    "output_image = image_manipulation.np_to_pil(\n",
    "    generator(generator(transform(original_image).unsqueeze(0).to(device))).detach().cpu().numpy()[0]\n",
    ").resize((256, 256))\n",
    "\n",
    "new_image = Image.new(output_image.mode, (256 * 2, 256))\n",
    "\n",
    "new_image.paste(original_image, (0, 0))\n",
    "new_image.paste(output_image, (256, 0))\n",
    "\n",
    "new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "761303e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), \"saved_models/generator.pth\")\n",
    "torch.save(discriminator.state_dict(), \"saved_models/discriminator.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a604c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/imsanskar/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "def fid(img1_vec, img2_vec) -> float:\n",
    "    #calculate mean\n",
    "    mu1, C1 = img1_vec.mean(axis = 0), np.cov(img1_vec, rowvar = False)\n",
    "    mu2, C2 = img2_vec.mean(axis = 0), np.cov(img2_vec, rowvar = False)\n",
    "\n",
    "    # sum of squared difference\n",
    "    msdiff = np.sum((mu1 - mu2) ** 2)\n",
    "\n",
    "    # sqrt of products\n",
    "    product_covariance = sqrtm(C1.dot(C2)) \n",
    "    if np.iscomplexobj(product_covariance):\n",
    "        product_covariance = product_covariance.real\n",
    "\n",
    "    sqrt_product_covariance = np.trace(C1 + C2 - 2 * product_covariance)\n",
    "    #return the result\n",
    "    return msdiff + sqrt_product_covariance\n",
    "\n",
    "def calculate_fid(model, images_1, images_2):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(299),\n",
    "#         transforms.CenterCrop(299),\n",
    "#         transforms.ToTensor(),\n",
    "    ])\n",
    "    images_1 = preprocess(images_1)\n",
    "    images_2 = preprocess(images_2)\n",
    "    img1_vec = model(preprocess(images_1)).detach().cpu().numpy()\n",
    "    img2_vec = model(preprocess(images_2)).detach().cpu().numpy()\n",
    "    return fid(img1_vec, img2_vec)\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "        transforms.Resize(299),\n",
    "        # transforms.CenterCrop(299),\n",
    "        # transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True, progress=False)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "439c71b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 646.00 MiB (GPU 0; 5.80 GiB total capacity; 3.46 GiB already allocated; 418.81 MiB free; 4.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_451423/660061831.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataloader_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimages_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mimages_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg1_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/imsanskar/My_files/Projects/Minor/env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_451423/1204503335.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mu7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/imsanskar/My_files/Projects/Minor/env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/imsanskar/My_files/Projects/Minor/env/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/imsanskar/My_files/Projects/Minor/env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/imsanskar/My_files/Projects/Minor/env/lib/python3.9/site-packages/torch/nn/modules/padding.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/imsanskar/My_files/Projects/Minor/env/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_pad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   4172\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Padding length too large\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"constant\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_pad_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4175\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4176\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Padding mode \"{}\"\" doesn\\'t take in value argument'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 646.00 MiB (GPU 0; 5.80 GiB total capacity; 3.46 GiB already allocated; 418.81 MiB free; 4.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "dataloader_list = next(iter(dataloader))\n",
    "len(dataloader_list)\n",
    "images_1 = preprocess(generator(dataloader_list['A'].to(device)))\n",
    "images_2 = preprocess(dataloader_list['B']).to(device)\n",
    "img1_vec = model(preprocess(images_1)).detach().cpu().numpy()\n",
    "img2_vec = model(preprocess(images_2)).detach().cpu().numpy()\n",
    "fid(np.transpose(img1_vec), np.transpose(img2_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e33bfea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bac7715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "988ce391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb7f8f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27220766433376997"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "465b0acfc40bb57cb596125d35bd7c1cb1a96ff7d828a469853b9c25f456647d"
  },
  "kernelspec": {
   "display_name": "minor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
